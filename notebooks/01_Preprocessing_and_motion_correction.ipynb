{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior, preprocessing and motion correction\n",
    "\n",
    "Welcome to the CaImAn processing pipeline! With these notebooks you can perform all necessary established processing and analysis steps in pre-formatted, easy-to-use chunks. \n",
    "\n",
    "Currently these steps are:\n",
    " 1. **Align and validate behavior**: Align the different behavioral files produces by LabView. Then plot licking and running data over time to remove trials with faulty recording.\n",
    " 1. **Preprocessing and motion correction**: Take the raw .tif file, do some preprocessing and perform motion correction built into CaImAn. The results are saved as one big .mmap file per recording session.\n",
    " 2. **Source extraction**: Take the .mmap file and use CaImAn to extract ROIs (putative neurons) and their calcium data from the movie. Results are saved in a CNM object HDF5 file.\n",
    " 3. **Component evaluation**: Load the CNM object and perform component evaluation. This does a quality check and only keeps ROIs that are actually active neurons. Results are saved by updating the cnm.hdf5 file\n",
    " 4. **Place cell detection**: Load the finished CNM object and perform the first established step of \"true\" analysis: finding place cells. The results (including the cnm object) is saved in a new `pcf_results.pickle` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align and validate behavior\n",
    "\n",
    "The first thing you want to do after recording a session is to validate that the behavior was recorded properly. For this you first run the `align_behavior()` script that combines the different files produced by LabView. Then you can plot the licking and speed data across time, not aligned to the VR position (for now we only care about the raw behavior). If e.g. the licking sensor was permanently activated and lickings might have been missed, its better to delete the trial now before processing rather than let the faulty recording corrupt the performance analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../custom scripts/')\n",
    "\n",
    "import standard_pipeline.behavior_import as behavior\n",
    "import standard_pipeline.performance_check as performance\n",
    "\n",
    "root = r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5'\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start processing session W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M62\\20210222...\n",
      "Done!\n",
      "\n",
      "\n",
      "Start processing session W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M63\\20210222...\n",
      "Done!\n",
      "\n",
      "\n",
      "Start processing session W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M65\\20210222...\n",
      "Done!\n",
      "\n",
      "\n",
      "Start processing session W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M68\\20210222...\n",
      "Trial incomplete, please remove file!\n",
      "Skipped trial W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M68\\20210222\\Encoder data20210222_171051.txt, please check!\n",
      "Done!\n",
      "\n",
      "\n",
      "Start processing session W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5\\M69\\20210222...\n",
      "Done!\n",
      "\n",
      "\n",
      "Everything processed!\n"
     ]
    }
   ],
   "source": [
    "# First, we merge the behavioral files into one. If performance_check=True, the licking/stopping ratio is saved\n",
    "behavior.align_behavior(root, performance_check=True, verbose=False, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch6\\M71\\20210222\\merged_behavior_100120.txt\n",
      "W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch6\\M71\\20210222\\merged_behavior_95701.txt\n"
     ]
    }
   ],
   "source": [
    "# Now check if any trials show bad/faulty behavior recording (e.g. constantly activated licking sensor)\n",
    "# Do this for each mouse/session separately. Manually remove bad trials from the session folder\n",
    "%matplotlib qt\n",
    "performance.quick_screen_session(r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch6\\M71\\20210222')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After filtering out bad trials, you can load the performance data and plot it\n",
    "# DOES NOT WORK IN NOTEBOOK?\n",
    "%matplotlib qt\n",
    "path = [r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5']\n",
    "data = performance.load_performance_data(roots=path,norm_date='0', ignore=None)\n",
    "performance.plot_all_mice_separately(data, field='licking_binned', rotate_labels=False, scale=1.75, vlines=None, columns=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and motion correction\n",
    "\n",
    "The first step we want to do is preprocess our raw .tif files. There are two problems with the .tif files produced by Scanimage that we want to correct before proceeding with the actual processing.\n",
    "\n",
    "\n",
    "First, even and odd lines can be (slightly) misaligned if the settings of the microscope have not been set properly before the session. This can be corrected by calculating the crosscorrelation between even and odd lines and shifting them by the number of pixels that maximise the correlation.\n",
    "\n",
    "\n",
    "Second, the pixel values coming from the microscope have arbitrary units, which is why we later transform the values into a normalized form which is comparable between neurons, sessions and microscopes. Thus, the absolute pixel intensity is not really relevant for later analysis. However, the Scientifica microscope that we are using to acquire the data scales the data so that the noise distribution is centered on 0. This causes up to half of the values (at least without calcium transients) to actually be negative. This is a problem because CaImAn uses a model called **non-negative** matrix factorization, which assumes that all values are positive (which kind of makes sense, you cannot have \"negative\" fluorescence). This can be corrected by shifting all pixel values by a certain amount to eliminate negative values.\n",
    "\n",
    "After this is done, CaImAn performs motion correction and saves the result as a mmap file in the session folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "sys.path.append('../custom scripts/')\n",
    "\n",
    "import standard_pipeline.place_cell_pipeline as pipe\n",
    "import standard_pipeline.behavior_import as behavior\n",
    "import matplotlib.pyplot as plt\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "import numpy as np\n",
    "\n",
    "# Start cluster for parallel processing\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=None, single_thread=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parameters\n",
    "\n",
    "root = r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch5'\n",
    "\n",
    "# dataset dependent parameters\n",
    "fr = 30  # imaging rate in frames per second\n",
    "decay_time = 0.4  # length of a typical transient in seconds (0.4)\n",
    "dxy = (1.66, 1.52)   # spatial resolution in x and y in (um per pixel) [(1.66, 1.52) for 1x, (0.83, 0.76) for 2x]\n",
    "max_shift_um = (100., 100.)  # maximum shift in um\n",
    "patch_motion_um = (250., 250.)  # patch size for non-rigid correction in um, default (250,250)\n",
    "\n",
    "# motion correction parameters\n",
    "pw_rigid = True  # flag to select rigid vs pw_rigid motion correction\n",
    "# maximum allowed rigid shift in pixels\n",
    "max_shifts = [int(a / b) for a, b in zip(max_shift_um, dxy)]\n",
    "# start a new patch for pw-rigid motion correction every x pixels\n",
    "strides = tuple([int(a / b) for a, b in zip(patch_motion_um, dxy)])\n",
    "# overlap between patches (size of patch in pixels: strides+overlaps)\n",
    "overlaps = (32, 32)   #default (12,12)\n",
    "# maximum deviation allowed for patch with respect to rigid shifts\n",
    "max_deviation_rigid = 3\n",
    "# number of iterations for motion correction (set to 2 for strong artifacts)\n",
    "niter_rig = 2\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': None,\n",
    "    'fr': fr,\n",
    "    'decay_time': decay_time,\n",
    "    'dxy': dxy,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': 'copy',\n",
    "    'n_processes': n_processes,\n",
    "    'niter_rig': niter_rig\n",
    "}\n",
    "\n",
    "opts = cnmf.params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "motion_file, dview = pipe.motion_correction(root, opts, dview, basename = 'Frontal_recording', percentile=0.01, get_images=True, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To check the motion-corrected movie, we can save it as a TIFF file and open it in ImageJ\n",
    "pipe.export_tif(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set parameters\n",
    "import div.file_manager as fm\n",
    "roots = [r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch3\\M41\\20200826',\n",
    "         r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch3\\M41\\20200824']\n",
    "\n",
    "fm.transfer_raw_movies(r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch3\\M41\\20200826',\n",
    "                        target= r'E:\\Batch3\\M41\\20200826')\n",
    "fm.transfer_raw_movies(r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch3\\M41\\20200824',\n",
    "                        target= r'E:\\Batch3\\M41\\20200824')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
