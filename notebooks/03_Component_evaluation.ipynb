{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component evaluation\n",
    "\n",
    "Here we take a CNM object and evaluate all of its components to filter out false positives and only keep real neurons.\n",
    "\n",
    "The evaluation is done following these criteria:\n",
    "\n",
    " - Spatial footprint consistency (rval): The spatial footprint of the component is compared with the frames where this component is active. Other componentâ€™s signals are subtracted from these frames, and the resulting raw data is correlated against the spatial component. This ensures that the raw data at the spatial footprint aligns with the extracted trace.\n",
    " - Trace signal-noise-ratio (SNR): Peak SNR is calculated from strong calcium transients and the noise estimate.\n",
    " - CNN-based classifier (cnn): The shape of components is evaluated by a 4-layered convolutional neural network trained on a manually annotated dataset. The CNN assigns a value of 0-1 to each component depending on its resemblance to a neuronal soma.\n",
    "\n",
    "Each parameter has a low threshold (*rval_lowest* (default -1), *SNR_lowest* (default 0.5), *cnn_lowest* (default 0.1)) and high threshold (*rval_thr* (default 0.8), *min_SNR* (default 2.5), *min_cnn_thr* (default 0.9)). A component has to exceed ALL low thresholds as well as ONE high threshold to be accepted.\n",
    "\n",
    "You will have to run the evaluation several times, check how the evaluation looks (if neurons are accepted and noise is rejected), adjust the parameters and run the evaluation again. Repeat this process until (almost) all neurons are accepted with as little false-positives as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "sys.path.append('../custom scripts/')\n",
    "\n",
    "from caiman.source_extraction import cnmf\n",
    "import standard_pipeline.place_cell_pipeline as pipe\n",
    "import standard_pipeline.behavior_import as behavior\n",
    "import place_cell_class as pc\n",
    "import caiman as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import standard_pipeline.performance_check as performance\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Start cluster for parallel processing\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "First, we load the CNM object that holds the pre-selected components. We also have to load the memmapped movie, which is used during evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No file with the name W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch7\\M91\\20210718\\cnm_results.hdf5 found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1a4392eba693>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Load CNM object with pre-selected components\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcnm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_cnmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cnm_pre_selection.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Load movie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Caiman\\custom scripts\\standard_pipeline\\place_cell_pipeline.py\u001b[0m in \u001b[0;36mload_cnmf\u001b[1;34m(root, cnm_filename)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnm_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcnm_filename\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cnm_results.hdf5'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_cnmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cnm_results.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file with the name {cnm_filepath} found.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Caiman\\custom scripts\\standard_pipeline\\place_cell_pipeline.py\u001b[0m in \u001b[0;36mload_cnmf\u001b[1;34m(root, cnm_filename)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mload_cnmf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'cnm_results.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'No file with the name {cnm_filepath} found.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Loading file {cnm_file[0]}...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No file with the name W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch7\\M91\\20210718\\cnm_results.hdf5 found."
     ]
    }
   ],
   "source": [
    "# Set directory of the session\n",
    "root = r'W:\\Neurophysiology-Storage1\\Wahl\\Hendrik\\PhD\\Data\\Batch7\\M91\\20210718'\n",
    "\n",
    "# Load CNM object with pre-selected components\n",
    "cnm = pipe.load_cnmf(root, 'cnm_pre_selection.hdf5')\n",
    "\n",
    "# Load movie\n",
    "mmap_file, images = pipe.load_mmap(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters and run evaluation\n",
    "\n",
    "Now we set the parameters and run the evaluation. Afterwards, we plot the contours of accepted and rejected components to be able to check the evaluation. Are all neurons accepted? Are obvious non-neurons rejected? If necessary, adjust parameters and run the cell again until the results are satisfactorily (all neurons accepted, as few false positives as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "# Load local correlation image (should have been created during motion correction)\n",
    "try:\n",
    "    cnm.estimates.Cn = io.imread(root + r'\\local_correlation_image.tif')\n",
    "except FileNotFoundError:\n",
    "    pipe.save_local_correlation(images, root)\n",
    "    cnm.estimates.Cn = io.imread(root + r'\\local_correlation_image.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING MODEL:C:\\Users\\hheise\\caiman_data\\model\\cnn_model.json\n",
      "1339/1339 [==============================] - 1s 506us/sample\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<caiman.source_extraction.cnmf.estimates.Estimates at 0x22959d18288>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Component evaluation\n",
    "\n",
    "# plot graphs as separate, interactive window\n",
    "%matplotlib qt     \n",
    "\n",
    "# evaluation parameters\n",
    "min_SNR = 6  # signal to noise ratio for accepting a component (default 2)\n",
    "SNR_lowest = 3\n",
    "rval_thr = 0.85  # space correlation threshold for accepting a component (default 0.85)\n",
    "rval_lowest = -1\n",
    "cnn_thr = 0.9  # threshold for CNN based classifier (default 0.99)\n",
    "cnn_lowest = 0.2  # neurons with cnn probability lower than this value are rejected (default 0.1)\n",
    "\n",
    "cnm.params.set('quality', {'SNR_lowest': SNR_lowest,\n",
    "                           'min_SNR': min_SNR,\n",
    "                           'rval_thr': rval_thr,\n",
    "                           'rval_lowest': rval_lowest,\n",
    "                           'use_cnn': True,\n",
    "                           'min_cnn_thr': cnn_thr,\n",
    "                           'cnn_lowest': cnn_lowest})\n",
    "cnm = pipe.run_evaluation(images, cnm, dview=dview)\n",
    "\n",
    "cnm.estimates.plot_contours(img=cnm.estimates.Cn, idx=cnm.estimates.idx_components, display_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours(img=cnm.estimates.Cn, idx=cnm.estimates.idx_components, display_numbers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnm.estimates.view_components(images, img=cnm.estimates.Cn, idx=cnm.estimates.idx_components)\n",
    "cnm.estimates.view_components(images, img=cnm.estimates.Cn, idx=cnm.estimates.idx_components_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check single component\n",
    "\n",
    "To be able to better tune evaluation parameters, its possible to check the evaluation results of single components. This is possible with the function ``pipe.check_eval_results()``.\n",
    "\n",
    "This function needs the CNM object as a first argument and the ID of the requested cell. The ID is from the cnm.estimates.idx_components (if you want to check accepted components) or cnm.estimates.idx_components_bad (if you want to check rejected components). The index is the number displayed next to/inside the contour minus 1 (contours start counting at 1, python at 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.check_eval_results(cnm, cnm.estimates.idx_components[474], plot_contours=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot trace to check for real cells/transients (index is the global component index returned \n",
    "# from the check_eval_results() function)\n",
    "plt.figure()\n",
    "idx = 942\n",
    "plt.plot(cnm.estimates.C[idx]+cnm.estimates.R[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually accept cells if necessary (use indices of idx_components_bad)\n",
    "cnm = pipe.accept_cells(cnm, [109,111,143])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually reject cells if necessary (use indices of idx_components)\n",
    "cnm = pipe.reject_cells(cnm, [41, 42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results\n",
    "\n",
    "If the evaluation is good enough, the CaImAn pipeline is coming to an end. Select the components (which removes the data of all rejected components, so be sure about this step), detrend the calcium activity (dF/F), export the results as a contour plot and finally save the complete CNM object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the CNM object once before before deleting the data of rejected components\n",
    "pipe.save_cnmf(cnm, path=os.path.join(root, 'cnm_pre_selection.hdf5'), verbose=False, overwrite=True)\n",
    "\n",
    "# Select components, which keeps the data of accepted components and deletes the data of rejected ones\n",
    "cnm.estimates.select_components(use_object=True)\n",
    "\n",
    "# Detrend calcium data (compute dF/F). Note that the frame window should be big enough to be larger than the longest\n",
    "# actual transients, but shorter than slow changes in background fluorescence changes (e.g. due to slow z-drift)\n",
    "# A good measure is to adapt the window size to the movie length, e.g. by taking a fraction of the duration\n",
    "# Note that a larger frame window also increases the time of dF/F calculation\n",
    "#cnm.params.data['dff_window'] = int(len(cnm.estimates.C[0])/5)\n",
    "cnm.params.data['dff_window'] = 2000\n",
    "cnm.estimates.detrend_df_f(quantileMin=8, frames_window=cnm.params.data['dff_window'])\n",
    "\n",
    "# Save complete CNMF results\n",
    "pipe.save_cnmf(cnm, path=os.path.join(root, 'cnm_results.hdf5'), overwrite=False, verbose=False)\n",
    "\n",
    "# Plot contours of all accepted components\n",
    "cnm.estimates.plot_contours(img=cnm.estimates.Cn, display_numbers=False)\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches((10, 10))\n",
    "plt.savefig(os.path.join(root, 'components.png'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!\n",
    "\n",
    "Now you can proceed with the actual data analysis and [place cell detection](.\\\\Place_Cell_Detection.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
